# 多任务模型

## 多任务学习

多任务学习主要指的是, 本质上是希望通过使用一个模型对多个任务进行建模. 推荐系统中, 多任务学习常常是 Multi-Label 学习.

![](https://s1.vika.cn/space/2022/06/28/f705bcf79a2e498eaeb961983a67b965)

### 为什么使用多任务学习

1. 推荐的业务场景中天然是一种多目标的建模场景. 

	在业务中的任意一个场景下,   以短视频 app 为例,   有非常多的行为标签可以作为建模过程中考虑的因素. 如天然的视频完播率, 播放时长等目标, 以及点赞, 收藏, 点击作者页面, 关注,分享等标签. 在实际场景中, 我们需要考虑这些因素哪些对模型的作用更大, 哪些更加微弱.

	这些目标的反馈在进行处理时同样需要注意一些问题:
	1. 目标偏差: 不同目标标签可能具有不同的效益, 如收藏分享比播放的反馈更加正向.
	2. 物品偏差: 不同的物品也会对同一个指标产生影响, 如一些骗用户点到最后的视频完播率很高, 但不一定能得到足够的喜爱
	3. 用户偏差: 不同的用户表达满意度的方式不同, 有的人会点赞, 有的人会收藏.

2. 工程便利

	不用针对不同的任务训练不同的模型. 一般推荐系统中排序模块延时需求在40ms左右, 如果分别对每个任务单独训练一个模型, 难以满足需求. 出于控制成本的目的,  需要将部分模型进行合并. 合并之后,  能更高效的利用训练资源和进行模型的迭代升级.

### 模型细节

多任务学习的一大主流研究方向便是如何设计有效的网络结构. 多个label的引入自然带来了多个loss, 那么如何在联合训练中共同优化多个loss则是关键问题.

#### Loss 加权融合

对不同的任务的 Loss 进行加权, 如 YoutubeDNN 中的加权交叉熵:

$$Weight \ CE \ Loss = - \sum_i [T_i \ y_i \ logp_i + (1-y_i)log(1-p_i)] $$

其中 $T_i$ 是观看时间, 被点击的样本为正样本, 被推荐了但是没有被点击的视频为负样本. 那么通过加权考虑 $T_i$ , 就可以达到优化平均观看时长的模型效果.

这种loss加权的方式优点如下：

-   模型简单, 仅在训练时通过梯度乘以样本权重实现对其它目标的加权
-   模型上线简单, 和base完全相同, 不需要额外开销

缺点：

-   本质上并不是多目标建模, 而是将不同的目标转化为同一个目标. 样本的加权权重需要根据AB测试才能确定. 

#### Shared Bottom

通过共享底层模块, 学习任务间通用的特征表征, 再往上针对每一个任务设置一个Tower网络，每个Tower网络的参数由自身对应的任务目标进行学习. Shared Bottom可以根据自身数据特点, 使用MLP, DeepFM, DCN, DIN等, Tower网络一般使用简单的MLP. 

代码实现如下:

```Python
def Shared_Bottom(dnn_feature_columns, num_tasks=None, task_types=None, task_names=None,
                  bottom_dnn_units=[128, 128], tower_dnn_units_lists=[[64,32], [64,32]],
                  l2_reg_embedding=0.00001, l2_reg_dnn=0, seed=1024,dnn_dropout=0,
                  dnn_activation='relu', dnn_use_bn=False):

    features = build_input_features(dnn_feature_columns)
    inputs_list = list(features.values())
    
    sparse_embedding_list, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,seed)
    #共享输入特征
    dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)
    #共享底层网络
    shared_bottom_output = DNN(bottom_dnn_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)
    #任务输出层
    tasks_output = []
    for task_type, task_name, tower_dnn in zip(task_types, task_names, tower_dnn_units_lists):
        tower_output = DNN(tower_dnn, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed, name='tower_'+task_name)(shared_bottom_output)

        logit = tf.keras.layers.Dense(1, use_bias=False, activation=None)(tower_output)
        output = PredictionLayer(task_type, name=task_name)(logit) 
        tasks_output.append(output)

    model = tf.keras.models.Model(inputs=inputs_list, outputs=tasks_output)
    return model
```

## ESMM

ESMM (Entire Space Multi-Task Model) 为一个多任务模型, 本质上是以 CVR 为主任务, 引入 CTR 和 CTCVR 作为辅助任务, 解决 CVR 预估的挑战.

### 动机

传统的CVR预估问题存在着两个主要的问题: **样本选择偏差**和**稀疏数据** . 下图的白色背景是曝光数据, 灰色背景是点击行为数据, 黑色背景是购买行为数据. 传统CVR预估使用的训练样本仅为灰色和黑色的数据.

![](https://s1.vika.cn/space/2022/06/28/b5826dc1900944a1b28fd4726670bad6)

### 模型改进

阿里团队通过引入 CTR 和 CTCVR (已点击然后转化) , 来解决上述两个问题.

-   **pCTR**：p(click=1 | impression)；
-   **pCVR**: p(conversion=1 | click=1,impression)；
-   **pCTCVR**: p(conversion=1, click=1 | impression) = p(click=1 | impression) * p(conversion=1 | click=1, impression)；

通过上述的概率公式也可以看出, 三个指数的关系

![](https://s1.vika.cn/space/2022/06/28/64250a5b567442a1830a0b88108eac83)

其中x表示曝光, y表示点击, z表示转化. 针对这三个任务, 设计了如图所示的模型结构:

![](https://s1.vika.cn/space/2022/06/28/19d1bba7cb454c4ea9a03759ce3ab365)

模型的损失函数为:

![](https://s1.vika.cn/space/2022/06/28/f570f4962e2a4cd4a99319647be6092b)


### 代码实现

```Python
def ESSM(dnn_feature_columns, task_type='binary', task_names=['ctr', 'ctcvr'],
         tower_dnn_units_lists=[[128, 128],[128, 128]], l2_reg_embedding=0.00001, l2_reg_dnn=0,
         seed=1024, dnn_dropout=0,dnn_activation='relu', dnn_use_bn=False):

    features = build_input_features(dnn_feature_columns)
    inputs_list = list(features.values())

    sparse_embedding_list, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,seed)

    dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)

    ctr_output = DNN(tower_dnn_units_lists[0], dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)
    cvr_output = DNN(tower_dnn_units_lists[1], dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)

    ctr_logit = tf.keras.layers.Dense(1, use_bias=False, activation=None)(ctr_output)
    cvr_logit = tf.keras.layers.Dense(1, use_bias=False, activation=None)(cvr_output)

    ctr_pred = PredictionLayer(task_type, name=task_names[0])(ctr_logit)
    cvr_pred = PredictionLayer(task_type)(cvr_logit)

    ctcvr_pred = tf.keras.layers.Multiply(name=task_names[1])([ctr_pred, cvr_pred])#CTCVR = CTR * CVR

    model = tf.keras.models.Model(inputs=inputs_list, outputs=[ctr_pred, cvr_pred, ctcvr_pred])
    return model
```

## MMOE

